{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jeb Bush Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://stackoverflow.com/questions/37513355/converting-pandas-dataframe-into-spark-dataframe-error \n",
    "\n",
    "https://towardsdatascience.com/multi-class-text-classification-with-pyspark-7d78d022ed35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_directory = r'E:\\Corpora\\PII_Jeb_20190507'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DataFrame with text from a pickle\n",
    "df2 = pd.read_pickle(os.path.join(in_directory,'df_pickle_001.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8763 entries, 0 to 8762\n",
      "Data columns (total 7 columns):\n",
      "GUID             8763 non-null object\n",
      "Name             8763 non-null object\n",
      "MIME Type        8763 non-null object\n",
      "Kind             8763 non-null object\n",
      "Tags             8763 non-null object\n",
      "content          8763 non-null object\n",
      "minimum_label    8763 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 479.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sqlContext.createDataFrame(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"content\", outputCol=\"words\", pattern=\"\\\\W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "label_stringIdx = StringIndexer(inputCol = \"minimum_label\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|                GUID|                Name|           MIME Type|    Kind|                Tags|             content|       minimum_label|               words|            filtered|            features|label|\n",
      "+--------------------+--------------------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|fba3c4e5-719f-462...|RE: Agency for Wo...|application/vnd.m...|   Email|PII|ID|social_sec...|Subject: RE: Agen...|PII|ID|social_sec...|[subject, re, age...|[subject, re, age...|(10000,[0,1,2,3,4...|  1.0|\n",
      "|8af93e08-5904-467...|RE: Ed Curtiss-Ju...|application/vnd.m...|   Email|   PII|ID|bar_number|Subject: RE: Ed C...|   PII|ID|bar_number|[subject, re, ed,...|[subject, re, ed,...|(10000,[0,1,3,4,5...|  8.0|\n",
      "|be0e3edc-5c20-413...|Ed Curtiss-Judici...|application/vnd.m...|   Email|   PII|ID|bar_number|Subject: Ed Curti...|   PII|ID|bar_number|[subject, ed, cur...|[subject, ed, cur...|(10000,[0,1,3,5,7...|  8.0|\n",
      "|d1aba93c-dc66-4d5...| Resume ERC 2002.doc|application/vnd.m...|Document|PII|ID|date_of_birth|Edward R. Curtis\n",
      "...|PII|ID|date_of_birth|[edward, r, curti...|[edward, r, curti...|(10000,[0,1,2,4,5...|  2.0|\n",
      "|e7a6b17d-e4d3-463...|          RESUME.doc|application/vnd.m...|Document|PII|ID|date_of_birth|RESUME\n",
      "Rev. Betsy...|PII|ID|date_of_birth|[resume, rev, bet...|[resume, rev, bet...|(10000,[0,1,2,3,4...|  2.0|\n",
      "+--------------------+--------------------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(sdf)\n",
    "dataset = pipelineFit.transform(sdf)\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'GUID'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
